{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPnowDZCqgNo1n8Y7bXR7bw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fahriyegrl/food101_classification_model_tensorflow/blob/main/food_classification_project_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "DoXbLOAMM0hN"
      },
      "outputs": [],
      "source": [
        "## Getting food data from TensorFlow Dataset\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    name='food101',\n",
        "    split=['train', 'validation'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_info.features"
      ],
      "metadata": {
        "id": "v2aCi0M5N8Ut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34384edd-ed80-4704-adb9-57d85aa08a29"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FeaturesDict({\n",
              "    'image': Image(shape=(None, None, 3), dtype=uint8),\n",
              "    'label': ClassLabel(shape=(), dtype=int64, num_classes=101),\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ds_info.features['label'].names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "3LqN88dzOAKG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1aabc54-4479-439b-f75b-7827c4812543"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare', 'beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito', 'bruschetta', 'caesar_salad', 'cannoli', 'caprese_salad', 'carrot_cake', 'ceviche', 'cheesecake', 'cheese_plate', 'chicken_curry', 'chicken_quesadilla', 'chicken_wings', 'chocolate_cake', 'chocolate_mousse', 'churros', 'clam_chowder', 'club_sandwich', 'crab_cakes', 'creme_brulee', 'croque_madame', 'cup_cakes', 'deviled_eggs', 'donuts', 'dumplings', 'edamame', 'eggs_benedict', 'escargots', 'falafel', 'filet_mignon', 'fish_and_chips', 'foie_gras', 'french_fries', 'french_onion_soup', 'french_toast', 'fried_calamari', 'fried_rice', 'frozen_yogurt', 'garlic_bread', 'gnocchi', 'greek_salad', 'grilled_cheese_sandwich', 'grilled_salmon', 'guacamole', 'gyoza', 'hamburger', 'hot_and_sour_soup', 'hot_dog', 'huevos_rancheros', 'hummus', 'ice_cream', 'lasagna', 'lobster_bisque', 'lobster_roll_sandwich', 'macaroni_and_cheese', 'macarons', 'miso_soup', 'mussels', 'nachos', 'omelette', 'onion_rings', 'oysters', 'pad_thai', 'paella', 'pancakes', 'panna_cotta', 'peking_duck', 'pho', 'pizza', 'pork_chop', 'poutine', 'prime_rib', 'pulled_pork_sandwich', 'ramen', 'ravioli', 'red_velvet_cake', 'risotto', 'samosa', 'sashimi', 'scallops', 'seaweed_salad', 'shrimp_and_grits', 'spaghetti_bolognese', 'spaghetti_carbonara', 'spring_rolls', 'steak', 'strawberry_shortcake', 'sushi', 'tacos', 'takoyaki', 'tiramisu', 'tuna_tartare', 'waffles']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_example = ds_train.take(1)\n",
        "for image, label in train_example:\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())\n",
        "  print(\"Class name: \", class_names[label.numpy()])\n",
        "  print(type(image))\n",
        "  print(image.shape)"
      ],
      "metadata": {
        "id": "4VNNwvgUOO1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09678793-cd2a-4681-b368-e3592c731601"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape:  (512, 512, 3)\n",
            "Label:  21\n",
            "Class name:  chocolate_cake\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "(512, 512, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image"
      ],
      "metadata": {
        "id": "XhcbfqqAOgDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32170429-4492-41c3-e49f-a247c3583dd6"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(512, 512, 3), dtype=uint8, numpy=\n",
              "array([[[ 32,  14,   0],\n",
              "        [ 31,  13,   0],\n",
              "        [ 28,  12,   0],\n",
              "        ...,\n",
              "        [ 54,  34,  10],\n",
              "        [ 53,  33,   9],\n",
              "        [ 51,  31,   7]],\n",
              "\n",
              "       [[ 28,  10,   0],\n",
              "        [ 28,  10,   0],\n",
              "        [ 27,  11,   0],\n",
              "        ...,\n",
              "        [ 56,  36,  12],\n",
              "        [ 55,  35,  11],\n",
              "        [ 54,  34,   9]],\n",
              "\n",
              "       [[ 30,  12,   0],\n",
              "        [ 31,  13,   0],\n",
              "        [ 31,  15,   0],\n",
              "        ...,\n",
              "        [ 58,  38,  13],\n",
              "        [ 58,  38,  13],\n",
              "        [ 58,  38,  11]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[135,  80,   0],\n",
              "        [136,  81,   1],\n",
              "        [137,  82,   2],\n",
              "        ...,\n",
              "        [ 13,   6,   0],\n",
              "        [ 13,   6,   0],\n",
              "        [ 13,   6,   0]],\n",
              "\n",
              "       [[137,  82,   2],\n",
              "        [137,  82,   2],\n",
              "        [137,  82,   2],\n",
              "        ...,\n",
              "        [ 13,   6,   0],\n",
              "        [ 13,   6,   0],\n",
              "        [ 13,   6,   0]],\n",
              "\n",
              "       [[136,  81,   1],\n",
              "        [135,  80,   0],\n",
              "        [135,  80,   0],\n",
              "        ...,\n",
              "        [ 14,   7,   1],\n",
              "        [ 14,   7,   1],\n",
              "        [ 14,   7,   1]]], dtype=uint8)>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Preprocessing for data\n",
        "\n",
        "def prepocess_image(image, label):\n",
        "  image = tf.image.resize(image, (224, 224))\n",
        "  #image = image / 255.0\n",
        "  return tf.cast(image, tf.float32), label"
      ],
      "metadata": {
        "id": "MG_upw1DOGoj"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_preprocessed = prepocess_image(image, label)\n",
        "\n",
        "image.shape, image_preprocessed[0].shape"
      ],
      "metadata": {
        "id": "IgQITD13O80I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78f11839-265d-44e2-dea1-f83d5e5a6f10"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([512, 512, 3]), TensorShape([224, 224, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Preparing datasets into batches by using tf.data\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "ds_train = ds_train.map(map_func=prepocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_train = ds_train.shuffle(buffer_size=1000).batch(batch_size=BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "ds_test = ds_test.map(map_func=prepocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_test = ds_test.batch(batch_size=BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iw2foklDUDCv"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train, ds_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OGyGG3Ppop5",
        "outputId": "81ef04b9-1b19-4023-cb63-33b20a8e000e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>,\n",
              " <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_example = ds_train.take(1)\n",
        "for image, label in train_example:\n",
        "  print(\"Image shape: \", image.shape)\n",
        "  print(\"Label: \", label.numpy())\n",
        "  #print(\"Class name: \", class_names[label.numpy()])\n",
        "  print(type(image))"
      ],
      "metadata": {
        "id": "IhiGVL5zIb8y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fea4d18a-ca14-4132-9202-fcd1cc5b200a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape:  (32, 224, 224, 3)\n",
            "Label:  [47 37 77 84 49 66 55 22 13 67 13 76 44 86 80 49 38 92  5 40 18  3 64 53\n",
            " 96 33 48 51 14  0 75  8]\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TensorBorad callbacks\n",
        "\n",
        "check_path = \"model_checkpoint/cp.weights.h5\"\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=check_path,\n",
        "                                                 monitor='val_accuracy',\n",
        "                                                 save_best_only=True,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=0)"
      ],
      "metadata": {
        "id": "yiUyVkktVb6e"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Setting mixed precision training\n",
        "import tensorflow as tf\n",
        "from keras import mixed_precision\n",
        "\n",
        "mixed_precision.set_global_policy('mixed_float16')\n"
      ],
      "metadata": {
        "id": "dSWKCe1rWGbE"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mixed_precision.global_policy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O_nhqp8syoL",
        "outputId": "b6df841d-a8b6-4a1e-84df-fbdac97f413b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DTypePolicy \"mixed_float16\">"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH-8gQVDq5Rv",
        "outputId": "d7ec796d-addb-4435-bfd2-1f58fe90d054"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### creating a model\n",
        "\n",
        "from keras import mixed_precision\n",
        "from keras import layers\n",
        "\n",
        "#mixed_precision.set_global_policy('mixed_float16')\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = layers.Input(shape=input_shape, name='input_layer')\n",
        "x = base_model(inputs, training=False)\n",
        "x = layers.GlobalAveragePooling2D(name=\"pooling_layer\")(x)\n",
        "x = layers.Dense(len(class_names))(x)\n",
        "outputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "yHQ2VA2MW3Wv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42e74e64-ac99-44e8-f687-5eab310abaf4"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "38PJFAJMXQiM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "fb9ae43d-639c-4f00-dac4-cb7d62e004c6"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m4,049,571\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pooling_layer                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)                 │         \u001b[38;5;34m129,381\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ softmax_float32 (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pooling_layer                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">129,381</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ softmax_float32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,178,952\u001b[0m (15.94 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,178,952</span> (15.94 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m129,381\u001b[0m (505.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129,381</span> (505.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "  print(layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "Nplxen47YF-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac52b462-0dd4-4de4-a057-003905380379"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_layer True\n",
            "efficientnetb0 False\n",
            "pooling_layer True\n",
            "dense_2 True\n",
            "softmax_float32 True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CNpSLMeIVXol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Fitting te model\n",
        "initial_epochs = 3\n",
        "\n",
        "#cardinality = tf.data.experimental.cardinality(ds_test).numpy()\n",
        "#if cardinality == tf.data.INFINITE_CARDINALITY:\n",
        "#    validation_steps = None  # Let Keras handle the validation steps for infinite datasets\n",
        "#else:\n",
        "#    validation_steps = int(0.15 * cardinality)\n",
        "\n",
        "history = model.fit(ds_train,\n",
        "                    epochs=initial_epochs,\n",
        "                    steps_per_epoch=len(ds_train),\n",
        "                    validation_data=ds_test,\n",
        "                    validation_steps=int(0.15 * len(ds_test)),\n",
        "                    #validation_steps=validation_steps,\n",
        "                    callbacks=[cp_callback])"
      ],
      "metadata": {
        "id": "bMYnYztHYNx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e3ea07c-f5de-4f4d-f4e9-82c8c12b4a6a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 31ms/step - accuracy: 0.7018 - loss: 1.1474 - val_accuracy: 0.7095 - val_loss: 1.1138\n",
            "Epoch 2/3\n",
            "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 967us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.6997 - val_loss: 1.1080\n",
            "Epoch 3/3\n",
            "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 27ms/step - accuracy: 0.7114 - loss: 1.1208 - val_accuracy: 0.6957 - val_loss: 1.1019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## evaluate the model\n",
        "#squeezed_ds_test = tf.squeeze(image, axis=0)\n",
        "\n",
        "result_feature_extraction = model.evaluate(ds_test)\n",
        "result_feature_extraction"
      ],
      "metadata": {
        "id": "axvBp-qfYfVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6006f96-2b8d-41b4-8438-003eded5b040"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 0.7019 - loss: 1.1051\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0987850427627563, 0.7052277326583862]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save(\"model_checkpoint/cp.weights.h5\")\n",
        "import keras\n",
        "\n",
        "model.save('model.keras')"
      ],
      "metadata": {
        "id": "1pNLZaH_w5WF"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_loaded = keras.models.load_model('model.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Sqk82SgymND",
        "outputId": "397be760-b9fe-475d-98c5-f2cd1560f22d"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'loss_scale_optimizer', because it has 8 variables whereas the saved optimizer has 10 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 4 variables whereas the saved optimizer has 6 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_loaded.evaluate(ds_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_QB3T2Ayvaz",
        "outputId": "d89260c9-a609-4e48-f1c8-0ffc257311a3"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - accuracy: 0.6988 - loss: 1.1104\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1054044961929321, 0.7029703259468079]"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Fine tuning the model\n",
        "\n",
        "model_loaded.summary()"
      ],
      "metadata": {
        "id": "ZCFE6pZ_ZYEQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "b6458ac5-abc2-4fcf-97e7-c13c66dedaa9"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m4,049,571\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pooling_layer                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)                 │         \u001b[38;5;34m129,381\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ softmax_float32 (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pooling_layer                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">129,381</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ softmax_float32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,308,339\u001b[0m (16.44 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,308,339</span> (16.44 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m129,381\u001b[0m (505.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129,381</span> (505.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m129,387\u001b[0m (505.43 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129,387</span> (505.43 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_loaded.layers:\n",
        "  layer.trainable = True\n",
        "  print(layer.name, layer.trainable,  layer.dtype, layer.dtype_policy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFt90CObzVBX",
        "outputId": "292062ea-a7c8-415b-bf8d-699743a43853"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_layer True float32 <DTypePolicy \"mixed_float16\">\n",
            "efficientnetb0 True float32 <DTypePolicy \"mixed_float16\">\n",
            "pooling_layer True float32 <DTypePolicy \"mixed_float16\">\n",
            "dense_2 True float32 <DTypePolicy \"mixed_float16\">\n",
            "softmax_float32 True float32 <DTypePolicy \"float32\">\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_loaded.layers[1].layers[:10]:\n",
        "  layer.trainable = True\n",
        "  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Swgw7fazgyp",
        "outputId": "9ca5ce1b-d3c0-4bb4-dee5-bf29cec5eee6"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_layer_2 True float32 <DTypePolicy \"mixed_float16\">\n",
            "rescaling True float32 <DTypePolicy \"mixed_float16\">\n",
            "normalization True float32 <DTypePolicy \"mixed_float16\">\n",
            "rescaling_1 True float32 <DTypePolicy \"mixed_float16\">\n",
            "stem_conv_pad True float32 <DTypePolicy \"mixed_float16\">\n",
            "stem_conv True float32 <DTypePolicy \"mixed_float16\">\n",
            "stem_bn True float32 <DTypePolicy \"mixed_float16\">\n",
            "stem_activation True float32 <DTypePolicy \"mixed_float16\">\n",
            "block1a_dwconv True float32 <DTypePolicy \"mixed_float16\">\n",
            "block1a_bn True float32 <DTypePolicy \"mixed_float16\">\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"fine_tune_checkpoints.keras\"\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                      save_best_only=True,\n",
        "                                                      monitor=\"val_loss\")"
      ],
      "metadata": {
        "id": "A9Kl53Uc0fGY"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_loaded.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "3y3nQOaZaLIW"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_num, layer in enumerate(model_loaded.layers[1].layers[:10]):\n",
        "  print(layer_num, layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "oz8R0pmnac43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567b8c35-c4cf-4fd2-8513-6668c2a897e1"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_layer_2 True\n",
            "1 rescaling True\n",
            "2 normalization True\n",
            "3 rescaling_1 True\n",
            "4 stem_conv_pad True\n",
            "5 stem_conv True\n",
            "6 stem_bn True\n",
            "7 stem_activation True\n",
            "8 block1a_dwconv True\n",
            "9 block1a_bn True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating learning rate reduction callback\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
        "                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n",
        "                                                 patience=2,\n",
        "                                                 verbose=1, # print out when learning rate goes down\n",
        "                                                 min_lr=1e-7)"
      ],
      "metadata": {
        "id": "haQuXwjo2Zwt"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", # watch the val loss metric\n",
        "                                                  patience=3) # if val loss decreases for 3 epochs in a row, stop training\n",
        "\n",
        "# Create ModelCheckpoint callback to save best model during fine-tuning\n",
        "checkpoint_path = \"fine_tune_checkpoints.keras\"\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                      save_best_only=True,\n",
        "                                                      monitor=\"val_loss\")"
      ],
      "metadata": {
        "id": "QXHibn0C24a3"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history_fine_tuning = model_loaded.fit(ds_train,\n",
        "                                epochs=50,\n",
        "                                steps_per_epoch=len(ds_train),\n",
        "                                validation_data=ds_test,\n",
        "                                validation_steps=int(0.15 * len(ds_train)),\n",
        "                                callbacks=[model_checkpoint, reduce_lr, early_stopping])\n"
      ],
      "metadata": {
        "id": "n01sKf16ah9C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76164488-1bda-47e9-d5fc-6f7963feca34"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 97ms/step - accuracy: 0.6194 - loss: 1.4987 - val_accuracy: 0.7915 - val_loss: 0.7445 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7963 - val_loss: 0.7349 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 78ms/step - accuracy: 0.7883 - loss: 0.7849 - val_accuracy: 0.7992 - val_loss: 0.7012 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8069 - val_loss: 0.6753 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 79ms/step - accuracy: 0.8542 - loss: 0.5443 - val_accuracy: 0.8246 - val_loss: 0.6439 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 685us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8126 - val_loss: 0.6636 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m2367/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.8963 - loss: 0.3914\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 78ms/step - accuracy: 0.8963 - loss: 0.3914 - val_accuracy: 0.8175 - val_loss: 0.6521 - learning_rate: 1.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8225 - val_loss: 0.6548 - learning_rate: 2.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_loaded.save(\"model_fine_tune.keras\")"
      ],
      "metadata": {
        "id": "2GTYe2bCa83A"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/fahriyegrl/model_deployment_Food101_effnetb2/blob/0c19059628140a7bd09b908c809e4a74eeab3ba2/images/IMG_1804.jpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olCV_6iB-uQP",
        "outputId": "a4de1aa4-f196-4d67-a58f-6c5413ed2e87"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-05 19:22:19--  https://github.com/fahriyegrl/model_deployment_Food101_effnetb2/blob/0c19059628140a7bd09b908c809e4a74eeab3ba2/images/IMG_1804.jpeg\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘IMG_1804.jpeg’\n",
            "\n",
            "IMG_1804.jpeg           [ <=>                ] 264.37K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-08-05 19:22:20 (23.3 MB/s) - ‘IMG_1804.jpeg’ saved [270719]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def load_and_prep_image(filename, img_shape=224):\n",
        "  # Read in target file (an image)\n",
        "  img = tf.io.read_file(filename)\n",
        "\n",
        "  # Decode the read file into a tensor & ensure 3 colour channels\n",
        "  # (our model is trained on images with 3 colour channels and sometimes images have 4 colour channels)\n",
        "  img = tf.image.decode_image(img, channels=3)\n",
        "\n",
        "  # Resize the image (to the same size our model was trained on)\n",
        "  img = tf.image.resize(img, size = [img_shape, img_shape])\n",
        "\n",
        "  # Rescale the image (get all values between 0 and 1)\n",
        "  #img = img/255.\n",
        "  return img\n",
        "\n"
      ],
      "metadata": {
        "id": "-tnsUEkU-9Ws"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.pixelstalk.net/wp-content/uploads/2016/08/Free-Food-Images-Download.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8kIar_2Akej",
        "outputId": "0bde0fbe-f3f0-450c-ef99-2509b0f6ae29"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-05 19:34:54--  https://www.pixelstalk.net/wp-content/uploads/2016/08/Free-Food-Images-Download.jpg\n",
            "Resolving www.pixelstalk.net (www.pixelstalk.net)... 172.67.210.245, 104.21.61.136, 2606:4700:3032::6815:3d88, ...\n",
            "Connecting to www.pixelstalk.net (www.pixelstalk.net)|172.67.210.245|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Could not parse String-Transport-Security header\n",
            "Length: 1031197 (1007K) [image/jpeg]\n",
            "Saving to: ‘Free-Food-Images-Download.jpg.1’\n",
            "\n",
            "\r          Free-Food   0%[                    ]       0  --.-KB/s               \rFree-Food-Images-Do 100%[===================>]   1007K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-08-05 19:34:55 (134 MB/s) - ‘Free-Food-Images-Download.jpg.1’ saved [1031197/1031197]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://images7.alphacoders.com/389/389345.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3ruYFYiB4aw",
        "outputId": "7abadd52-573b-43a9-d108-b1b75dc9af96"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-05 19:34:57--  https://images7.alphacoders.com/389/389345.jpg\n",
            "Resolving images7.alphacoders.com (images7.alphacoders.com)... 104.20.75.132, 172.67.48.187, 104.20.76.132, ...\n",
            "Connecting to images7.alphacoders.com (images7.alphacoders.com)|104.20.75.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 582330 (569K) [image/jpeg]\n",
            "Saving to: ‘389345.jpg.1’\n",
            "\n",
            "\r389345.jpg.1          0%[                    ]       0  --.-KB/s               \r389345.jpg.1        100%[===================>] 568.68K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-08-05 19:34:57 (71.2 MB/s) - ‘389345.jpg.1’ saved [582330/582330]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the image\n",
        "image_tensor = load_and_prep_image(\"/content/389345.jpg\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YAR67sGEAcr9"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an extra axis to represent batch size (as the model expects a batch of images)\n",
        "image_tensor = tf.expand_dims(image_tensor, axis=0)"
      ],
      "metadata": {
        "id": "UhUwGFjlBn9E"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model_loaded.predict(image_tensor)\n",
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMYa2K8iAkEB",
        "outputId": "2efc7d6f-4507-4272-8f8e-1c5ea43c35b8"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.1240974e-03, 1.7242560e-09, 1.3888091e-06, 1.8722211e-07,\n",
              "        2.7669631e-07, 3.1599711e-07, 8.6892964e-05, 2.0201021e-08,\n",
              "        1.0114272e-04, 7.1211053e-07, 3.4167437e-07, 8.9131085e-08,\n",
              "        9.7714928e-07, 1.0361147e-06, 1.8371056e-03, 8.0692695e-07,\n",
              "        1.2652804e-02, 3.2417161e-06, 2.3209330e-07, 1.8795487e-07,\n",
              "        4.9608921e-08, 7.5985998e-04, 9.6823117e-03, 1.0202036e-05,\n",
              "        2.7543078e-05, 1.0083178e-05, 1.1670382e-07, 5.3150486e-04,\n",
              "        6.6896592e-07, 4.2133979e-03, 6.2242107e-06, 1.6578191e-04,\n",
              "        4.7166691e-06, 1.1248599e-05, 4.9623732e-06, 2.6561670e-06,\n",
              "        1.7419570e-06, 5.4060738e-08, 4.4817924e-08, 2.7116062e-05,\n",
              "        2.9747659e-06, 2.5954118e-04, 4.1590043e-05, 3.1053739e-06,\n",
              "        9.1244765e-08, 9.3802173e-06, 4.0745806e-05, 5.4484744e-08,\n",
              "        6.5464924e-08, 6.5622284e-05, 1.3590866e-07, 5.1291397e-07,\n",
              "        2.2545963e-05, 1.7697009e-04, 1.3200444e-06, 1.1876860e-04,\n",
              "        2.9454171e-07, 8.4083722e-06, 3.1706624e-04, 2.2938930e-07,\n",
              "        4.7497317e-05, 1.7519322e-07, 1.5166234e-05, 3.4054560e-03,\n",
              "        1.2694742e-06, 2.0243537e-07, 8.3907122e-07, 8.6570623e-07,\n",
              "        1.8615609e-06, 1.4051800e-06, 2.2535867e-08, 3.0498981e-09,\n",
              "        9.4793421e-01, 2.4566866e-04, 1.8113484e-06, 5.8348252e-07,\n",
              "        5.8120764e-07, 2.7669631e-07, 3.3506578e-07, 9.7509705e-08,\n",
              "        7.7612995e-06, 6.1387766e-07, 3.1088719e-05, 3.2749947e-03,\n",
              "        1.5488659e-08, 2.9224958e-07, 3.0547013e-05, 2.8720015e-06,\n",
              "        1.2066182e-06, 7.5485698e-09, 1.8042869e-06, 4.8561719e-07,\n",
              "        9.1960402e-08, 1.4467403e-07, 2.1103697e-03, 2.6347097e-08,\n",
              "        4.2026664e-07, 1.2794309e-06, 8.0426112e-03, 2.0128273e-06,\n",
              "        2.4914849e-03]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.argmax(pred, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3S-2JO_BEbN",
        "outputId": "3466bcf6-ddf0-439f-f2a9-111af7d5cc10"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([72])>"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label = class_names[72]\n",
        "label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xb2TPiovBHew",
        "outputId": "eee8e52c-a2fd-42eb-ee9b-91b8e1658624"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pancakes'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    }
  ]
}